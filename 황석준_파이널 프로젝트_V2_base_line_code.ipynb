{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7BULvbSbsxv5nzmc7TRdJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip -q install streamlit\n","!pip -q install loguru\n","!pip -q install langchain\n","!pip -q install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rq6VMi6tv5_M","executionInfo":{"status":"ok","timestamp":1710382715189,"user_tz":-540,"elapsed":50362,"user":{"displayName":"황석준","userId":"10708726745828720778"}},"outputId":"fbbbc7ff-995a-46be-931c-6b441991285d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"W94XltBRpI1-","executionInfo":{"status":"ok","timestamp":1710382728439,"user_tz":-540,"elapsed":5810,"user":{"displayName":"황석준","userId":"10708726745828720778"}}},"outputs":[],"source":["import streamlit as st # stramlit(배포)\n","import tiktoken # token(토큰 기준으로 TextSplitter)\n","from loguru import logger # log(기록 남김)\n","\n","from langchain.chains import ConversationalRetrievalChain # RetrievalChain(참고 문서와 LLM 연결)\n","from langchain.chat_models import ChatOpenAI # LLM 모델 불러옴\n","\n","from langchain.document_loaders import PyPDFLoader #pdf loader\n","from langchain.document_loaders import Docx2txtLoader # word loader\n","from langchain.document_loaders import UnstructuredPowerPointLoader # ppt loader\n","\n","from langchain.text_splitter import RecursiveCharacterTextSplitter # TextSplitter(문서 분할)\n","from langchain.embeddings import HuggingFaceEmbeddings # embedding 모델 불러옴\n","\n","from langchain.memory import ConversationBufferMemory # 대화를 메모리에 넣음\n","from langchain.vectorstores import FAISS # vectorstore(벡터저장소)\n","\n","from langchain.callbacks import get_openai_callback\n","from langchain.memory import StreamlitChatMessageHistory"]},{"cell_type":"code","source":["def main():\n","  # 페이지 탭을 설정\n","  st.set_page_config(\n","  page_title=\"DirChat\",\n","  page_icon=\":books:\")\n","\n","  # 페이지 제목 설정\n","  st.title(\"_Private Data :red[QA Chat]_ :books:\")\n","\n","\n","  # st.session_state.conversation 을 초기화\n","  if \"conversation\" not in st.session_state:\n","        st.session_state.conversation = None\n","\n","  # st.session_state.chat_history 를 초기화\n","  if \"chat_history\" not in st.session_state:\n","      st.session_state.chat_history = None\n","\n","  if \"processComplete\" not in st.session_state:\n","      st.session_state.processComplete = None\n","\n","  # 좌측 사이드바 설정\n","  with st.sidebar:\n","    uploaded_files =  st.file_uploader(\"Upload your file\",type=['pdf','docx'],accept_multiple_files=True)\n","    openai_api_key = st.text_input(\"OpenAI API Key\", key=\"chatbot_api_key\", type=\"password\")\n","    process = st.button(\"Process\")\n","\n","  # 좌측 사이드바에서 process 버튼 처리\n","  if process:\n","    if not openai_api_key:\n","        st.info(\"Please add your OpenAI API key to continue.\")\n","        st.stop()\n","    files_text = get_text(uploaded_files) # 텍스트로 변환\n","    text_chunks = get_text_chunks(files_text) # 청크로 변환\n","    vetorestore = get_vectorstore(text_chunks) # 벡터 저장소에 저장\n","\n","    st.session_state.conversation = get_conversation_chain(vetorestore,openai_api_key) # chain\n","\n","    st.session_state.processComplete = True\n","\n","  # 챗봇의 첫머리\n","  if 'messages' not in st.session_state:\n","    st.session_state['messages'] = [{\"role\": \"AI developer job interviewer\",\n","                                      \"content\": \"안녕하세요! 간단한 자기소개 부탁드립니다.\"}]\n","\n","  #\n","  for message in st.session_state.messages:\n","    with st.chat_message(message[\"role\"]):\n","      st.markdown(message[\"content\"])\n","\n","  history = StreamlitChatMessageHistory(key=\"chat_messages\")\n","\n","  # Chat logic\n","  if query := st.chat_input(\"질문을 입력해주세요.\"):\n","    st.session_state.messages.append({\"role\": \"user\", \"content\": query})\n","\n","    with st.chat_message(\"user\"):\n","      st.markdown(query)\n","\n","    with st.chat_message(\"assistant\"):\n","      chain = st.session_state.conversation\n","\n","      with st.spinner(\"Thinking...\"):\n","        result = chain({\"question\": query})\n","        with get_openai_callback() as cb:\n","          st.session_state.chat_history = result['chat_history']\n","        response = result['answer']\n","        source_documents = result['source_documents']\n","\n","        st.markdown(response)\n","        with st.expander(\"참고 문서 확인\"):\n","          st.markdown(source_documents[0].metadata['source'], help = source_documents[0].page_content)\n","          st.markdown(source_documents[1].metadata['source'], help = source_documents[1].page_content)\n","          st.markdown(source_documents[2].metadata['source'], help = source_documents[2].page_content)\n","\n","    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n","\n","# 토큰 개수를 세는 함수\n","def tiktoken_len(text):\n","  tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n","  tokens = tokenizer.encode(text)\n","  return len(tokens)\n","\n","# 업로드된 파일을 텍스트화\n","def get_text(docs):\n","  doc_list = []\n","\n","  for doc in docs:\n","    file_name = doc.name  # doc 객체의 이름을 파일 이름으로 사용\n","    with open(file_name, \"wb\") as file:  # 파일을 doc.name으로 저장\n","      file.write(doc.getvalue())\n","      logger.info(f\"Uploaded {file_name}\")\n","    if '.pdf' in doc.name:\n","      loader = PyPDFLoader(file_name)\n","      documents = loader.load_and_split()\n","    elif '.docx' in doc.name:\n","      loader = Docx2txtLoader(file_name)\n","      documents = loader.load_and_split()\n","    elif '.pptx' in doc.name:\n","      loader = UnstructuredPowerPointLoader(file_name)\n","      documents = loader.load_and_split()\n","\n","    doc_list.extend(documents)\n","\n","  return doc_list\n","\n","def get_text_chunks(text):\n","  text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=900,\n","    chunk_overlap=100,\n","    length_function=tiktoken_len\n","  )\n","  chunks = text_splitter.split_documents(text)\n","  return chunks\n","\n","# embedding\n","def get_vectorstore(text_chunks):\n","  embeddings = HuggingFaceEmbeddings(\n","    model_name=\"jhgan/ko-sroberta-multitask\",\n","    model_kwargs={'device': 'cpu'},\n","    encode_kwargs={'normalize_embeddings': True}\n","  )\n","\n","  vectordb = FAISS.from_documents(text_chunks, embeddings)\n","  return vectordb\n","\n","def get_conversation_chain(vetorestore,openai_api_key):\n","  llm = ChatOpenAI(openai_api_key=openai_api_key, model_name = 'gpt-3.5-turbo',temperature=0)\n","  conversation_chain = ConversationalRetrievalChain.from_llm(\n","    llm=llm,\n","    chain_type=\"stuff\",\n","    retriever=vetorestore.as_retriever(search_type = 'mmr', vervose = True),\n","    memory=ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer'),\n","    get_chat_history=lambda h: h,\n","    return_source_documents=True,\n","    verbose = True\n","  )\n","\n","  return conversation_chain\n","\n","if __name__ == '__main__':\n","  main()"],"metadata":{"id":"Aydrlvexu5UY","executionInfo":{"status":"ok","timestamp":1710383209592,"user_tz":-540,"elapsed":482,"user":{"displayName":"황석준","userId":"10708726745828720778"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"X1F_frg8yJb1","executionInfo":{"status":"ok","timestamp":1710383209592,"user_tz":-540,"elapsed":3,"user":{"displayName":"황석준","userId":"10708726745828720778"}}},"execution_count":6,"outputs":[]}]}